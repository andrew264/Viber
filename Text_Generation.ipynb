{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "DELIMITER = '|'\n",
    "seq_length = 100\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "EPOCHS = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('dataset.csv', dtype=str, delimiter=DELIMITER).sample(frac=1)\n",
    "lyrics_list = []\n",
    "for index, row in dataset_df.iterrows():\n",
    "    lyrics = row[\"lyrics\"]\n",
    "    if isinstance(lyrics, str):\n",
    "        lyrics_list.append(lyrics.lower())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "lyrics = ' '.join(lyrics_list)\n",
    "vocab = sorted(set(lyrics))\n",
    "print(f'{len(vocab)} unique characters')\n",
    "\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "\n",
    "def text_from_ids(_ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(_ids), axis=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([41 40 40 ... 39 44 40], shape=(12945659,), dtype=int8)\n",
      "tf.Tensor(\n",
      "[b'f' b'e' b'e' b'l' b's' b' ' b'l' b'i' b'k' b'e' b' ' b't' b'i' b'm'\n",
      " b'e' b\"'\" b's' b' ' b'm' b'o' b'v' b'i' b'n' b'g' b' ' b'i' b'n' b' '\n",
      " b's' b'l' b'o' b'w' b' ' b'm' b'o' b't' b'i' b'o' b'n' b'\\n' b'j' b'u'\n",
      " b's' b't' b' ' b't' b'r' b'y' b'i' b'n' b'g' b' ' b't' b'o' b' ' b'o'\n",
      " b'c' b'c' b'u' b'p' b'y' b' ' b'm' b'y' b' ' b'm' b'i' b'n' b'd' b'\\n'\n",
      " b's' b'o' b' ' b't' b'h' b'a' b't' b' ' b'i' b' ' b'd' b'o' b'n' b\"'\"\n",
      " b't' b'g' b'o' b'l' b'o' b'o' b'n' b'e' b'y' b' ' b'o' b'v' b'e' b'r'\n",
      " b' ' b'y' b'o'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(lyrics, 'UTF-8'))\n",
    "all_ids = tf.cast(all_ids, dtype=tf.int8)\n",
    "print(all_ids)\n",
    "\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"feels like time's moving in slow motion\\njust trying to occupy my mind\\nso that i don'tgolooney over yo\"\n",
      "b'u\\njust trying to amplify the sound\\ntodrown out all of this need for you\\nbiting my nails, got me nervo'\n",
      "b\"us, so anxious\\nsee it's one o'clock now\\nnoon felt like three hours ago\\n\\ni just wanna know your e.t.a.\"\n",
      "b\", e.t.a.\\nout the window, got me looking out the street\\nwhat's your e.t.a.?\\ndistance only made us grow\"\n",
      "b\" fonder\\nof one another\\nbe honest, what's your e.t.a.?\\nwhat's your e.t.a.?\\nsay you almost right here n\"\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def split_input_target(sequence: list[str]) -> tuple[list[str], list[str]]:\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int8, name=None), TensorSpec(shape=(64, 100), dtype=tf.int8, name=None))>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = (\n",
    "    sequences\n",
    "    .map(split_input_target)\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.lstm = tf.keras.layers.LSTM(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.lstm.get_initial_state(x)\n",
    "    x, state1, state2  = self.lstm(x, initial_state=states, training=training)\n",
    "    states = (state1, state2)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model, ABC):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars, temperature=0.69)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am capable of light\n",
      "making bad girls are bright\n",
      "come on with me on your body\n",
      "work the chanel to my body\n",
      "how many nights i get the chance?\n",
      "like a freak shit, and i still look like my nigga got a nigga go\n",
      "what it feel a tool\n",
      "he call me cream, we sharpened by him\n",
      "do you like it when you say?\n",
      "'cause i'm not the one for you\n",
      "you don't want to say that i am everything\n",
      "you know i want ya\n",
      "i want you here right now\n",
      "you want me but i won't be sad when you're with my mum\n",
      "\n",
      "if this is all i want\n",
      "i'll live my life of you\n",
      "i'\n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "\n",
    "while True:\n",
    "    #string_input = input(\"Enter seed text: \")\n",
    "    string_input = \"i am capable of \"\n",
    "    if string_input == \"\":\n",
    "        break\n",
    "    string_input = tf.constant([string_input])\n",
    "    result = [string_input]\n",
    "    for n in range(500):\n",
    "      next_char, states = one_step_model.generate_one_step(string_input, states=states)\n",
    "      string_input = string_input + next_char\n",
    "\n",
    "    print(string_input.numpy()[0].decode())\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
